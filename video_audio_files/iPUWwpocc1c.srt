1
00:00:00,200 --> 00:00:03,806
Ever wondered about the differences between AI, ML, DL and

2
00:00:03,830 --> 00:00:06,854
ds? Well, we're about to explore all of those today.

3
00:00:06,934 --> 00:00:11,062
Stay tuned. So let's dive right into it. So AI versus ML versus

4
00:00:11,118 --> 00:00:14,862
DL versus DS, a whole bunch of jargon, but we're going to clarify

5
00:00:14,998 --> 00:00:18,318
all of that right up. So let's kick things off and take a look at

6
00:00:18,366 --> 00:00:21,790
AI. So AI is really to do

7
00:00:21,822 --> 00:00:25,662
with the ability of computers and machines to perform tasks without

8
00:00:25,758 --> 00:00:29,120
explicitly programming them, otherwise known as the ability

9
00:00:29,192 --> 00:00:32,044
for computers and machines to think by themselves.

10
00:00:32,384 --> 00:00:35,456
So we typically break out AI into two key categories.

11
00:00:35,560 --> 00:00:38,560
These are general AI and narrow AI.

12
00:00:38,752 --> 00:00:42,152
General AI typically refers to the ability for a computer or

13
00:00:42,168 --> 00:00:45,608
a machine to be able to handle a wide variety of tasks.

14
00:00:45,776 --> 00:00:48,920
Us as humans have the ability to do a whole heap of stuff. We can

15
00:00:48,952 --> 00:00:52,200
see, we can speak, we can hear, we can read, we can drive,

16
00:00:52,232 --> 00:00:55,598
we can do a whole range of things. The ability for AI

17
00:00:55,646 --> 00:00:59,390
and machines to be able to do a broad range of tasks similar to humans

18
00:00:59,422 --> 00:01:02,782
is what we typically refer to as general AI.

19
00:01:02,878 --> 00:01:06,414
Now, we're still a little bit of a while away from true general AI,

20
00:01:06,454 --> 00:01:09,238
but that's not to say it's not to come. Now,

21
00:01:09,326 --> 00:01:12,670
narrow AI, on the other hand, is the ability for a machine to

22
00:01:12,702 --> 00:01:15,862
handle a really simple or a really narrow range of tasks.

23
00:01:15,918 --> 00:01:20,230
So that could possibly be the ability to translate speech to text, or to classify

24
00:01:20,302 --> 00:01:23,558
images as having different categories, or the ability to predict

25
00:01:23,606 --> 00:01:27,186
house prices, for example, or all of these are examples of narrow

26
00:01:27,250 --> 00:01:30,490
AI. So I'm going to be painting a bunch of visual imagery to

27
00:01:30,522 --> 00:01:33,850
help you remember some of these topics. So the first one, in terms of breaking

28
00:01:33,882 --> 00:01:37,010
out general and narrow AI, or the ability to remember general and

29
00:01:37,042 --> 00:01:40,522
narrow AI, is just picture a really narrow or really

30
00:01:40,578 --> 00:01:43,986
skinny general in your mind. So that way you know that there's two different types

31
00:01:44,010 --> 00:01:47,266
of AI, general and narrow. Now onto the next topic,

32
00:01:47,330 --> 00:01:50,522
machine learning. So we've taken a look at AI as being broken up into general

33
00:01:50,578 --> 00:01:53,838
and narrow. But how does machine learning fit into this? Well,

34
00:01:53,966 --> 00:01:57,414
machine learning is the application of narrow AI to specific

35
00:01:57,494 --> 00:02:01,030
tasks. Now, when we typically talk about machine learning, we often compare

36
00:02:01,062 --> 00:02:04,406
it to traditional programming. So in traditional programming, we supply

37
00:02:04,470 --> 00:02:07,990
data plus rules or conditional logic, and we get answers.

38
00:02:08,102 --> 00:02:11,182
Now, in machine learning, on the other hand, we provide data

39
00:02:11,278 --> 00:02:14,790
plus historical answers to get rules. We can then pass new

40
00:02:14,822 --> 00:02:17,886
data to get new answers. So this is a bit of a change in the

41
00:02:17,910 --> 00:02:21,630
paradigm of how computer scientists and machine learning engineers are building

42
00:02:21,702 --> 00:02:24,814
programs these days. So what are some typical machine

43
00:02:24,854 --> 00:02:28,814
learning tasks? Well, we broadly break out machine learning into

44
00:02:28,934 --> 00:02:31,950
three key categories. These are supervised learning,

45
00:02:32,102 --> 00:02:35,390
unsupervised learning, and semi supervised learning. So let's take a look at

46
00:02:35,422 --> 00:02:38,990
supervised learning first. So, supervised learning can be broadly broken

47
00:02:39,022 --> 00:02:43,206
out into two key categories. These are classification and regression.

48
00:02:43,350 --> 00:02:46,662
Classification is all to do with grouping things into

49
00:02:46,718 --> 00:02:50,558
categories or labels. So say you had a big data set on all the different

50
00:02:50,606 --> 00:02:54,330
types of pizzas you've liked and whether or not you've liked them. Yes or no.

51
00:02:54,462 --> 00:02:58,114
You could take that data and pass it through to a classification algorithm

52
00:02:58,194 --> 00:03:01,394
to help it learn which types of pizzas you like. So then when you pass

53
00:03:01,434 --> 00:03:04,930
through a new list of ingredients, it would be able to predict, yes, you would

54
00:03:04,962 --> 00:03:08,634
like that pizza or no, you might not. Regression, on the other hand,

55
00:03:08,674 --> 00:03:12,170
is all to do with predicting continuous variables. Some great examples

56
00:03:12,202 --> 00:03:15,858
of regression are sales forecasting and predicting prices of houses.

57
00:03:15,906 --> 00:03:19,554
So that encapsulates supervised learning. Now, what about unsupervised learning?

58
00:03:19,674 --> 00:03:23,628
Well, there's two key things to think about when you think of unsupervised

59
00:03:23,676 --> 00:03:27,420
learning. These are really clustering. So the ability to group people together.

60
00:03:27,492 --> 00:03:31,388
So say you wanted to group together high performing and low performing and medium

61
00:03:31,436 --> 00:03:35,540
performing employees, or high value, low value, medium value customers,

62
00:03:35,612 --> 00:03:38,812
or a whole bunch of other different types of data. But really it's all to

63
00:03:38,828 --> 00:03:42,308
do with grouping things together. Now, dimensionality reduction, on the other

64
00:03:42,356 --> 00:03:46,156
hand, is all to do with condensing the features that you've got

65
00:03:46,180 --> 00:03:49,406
within a machine learning model. So a lot of the time you might start out

66
00:03:49,430 --> 00:03:52,814
with a huge data set with a lot of columns, and you're not really sure

67
00:03:52,854 --> 00:03:56,918
which of those columns are important for your machine learning model. Dimensionality reduction

68
00:03:56,966 --> 00:04:00,422
helps you reduce the number of columns that you've got so that you

69
00:04:00,438 --> 00:04:03,758
can really focus on the important ones. Now, in order

70
00:04:03,806 --> 00:04:06,998
to remember supervised learning and unsupervised learning,

71
00:04:07,166 --> 00:04:10,438
I'd suggest you remember this initialism, Christopher Robin

72
00:04:10,486 --> 00:04:14,030
caught a duck. So that way you remember classification, regression,

73
00:04:14,102 --> 00:04:18,067
clustering and dimensionality reduction. So that takes care of supervised

74
00:04:18,115 --> 00:04:20,931
and unsupervised learning. But what about semi supervised learning?

75
00:04:20,987 --> 00:04:24,163
Well, this is where reinforcement learning comes in. Now,

76
00:04:24,203 --> 00:04:27,667
reinforcement learning has four key things. These are an

77
00:04:27,715 --> 00:04:31,411
agent, an action, an environment, and a reward. It's similar

78
00:04:31,467 --> 00:04:35,171
to how you might choose to condition a dog. A dog might do something

79
00:04:35,227 --> 00:04:39,267
right and you might reward it with a piece of food. In a similar way,

80
00:04:39,315 --> 00:04:43,067
we train reinforcement learning models to act in a correct way in

81
00:04:43,075 --> 00:04:46,642
a given environment in order to learn appropriate actions given

82
00:04:46,698 --> 00:04:50,538
that specific environment. Now, the best way to remember reinforcement learning

83
00:04:50,586 --> 00:04:53,986
techniques is to remember area 51. So that way

84
00:04:54,010 --> 00:04:57,546
you remember agent reward environment and actions. Okay?

85
00:04:57,570 --> 00:05:00,618
So that takes care of machine learning. Now we're going to delve a little bit

86
00:05:00,666 --> 00:05:03,970
deeper and get into deep learning. So deep learning is a

87
00:05:04,002 --> 00:05:07,258
subset of machine learning, and really it's to do with performing

88
00:05:07,306 --> 00:05:10,680
machine learning tasks using deep neural networks.

89
00:05:10,802 --> 00:05:13,836
Now, deep neural networks are networks that have multiple

90
00:05:13,900 --> 00:05:17,564
hidden layers. So if you've ever seen a diagram that looks sort of like

91
00:05:17,604 --> 00:05:21,188
this, this is a representation of a neural network.

92
00:05:21,316 --> 00:05:24,788
But specifically in this case, this is a deep neural network because

93
00:05:24,836 --> 00:05:28,180
it has multiple hidden layers. Now, the best way to remember

94
00:05:28,252 --> 00:05:31,700
deep learning is to remember that deep learning is just like an onion.

95
00:05:31,772 --> 00:05:35,372
It has multiple layers, a little bit like Shrek. Now, that sort of

96
00:05:35,388 --> 00:05:38,720
covers AI, ML and DL. What about data science?

97
00:05:38,832 --> 00:05:42,688
Well, data science is the practice that sits over AI,

98
00:05:42,776 --> 00:05:46,880
ML and DL. It basically is the art of extracting

99
00:05:46,952 --> 00:05:50,360
knowledge, insight and meaning from data. The best way to remember the

100
00:05:50,392 --> 00:05:54,608
key components of data science are to look at the CrispDM framework.

101
00:05:54,736 --> 00:05:58,680
So the CrisPDM framework stands for the cross industry standard process

102
00:05:58,752 --> 00:06:02,680
for data mining. And basically it's a framework to help you along your way to

103
00:06:02,712 --> 00:06:06,494
producing really good data science projects. Now, there's six key

104
00:06:06,534 --> 00:06:10,390
steps in the data science process. These are business understanding.

105
00:06:10,462 --> 00:06:13,606
So understanding the business that you're working with and the environment in

106
00:06:13,630 --> 00:06:17,486
which they operate. Two data understanding. So understanding

107
00:06:17,510 --> 00:06:21,230
the data that you've got on hand. So whether or not you've got missing values,

108
00:06:21,302 --> 00:06:24,718
visualizing that data and taking a look at some summary statistics,

109
00:06:24,886 --> 00:06:28,598
we've then got data preparation. So this is all to do with getting our data

110
00:06:28,646 --> 00:06:32,230
ready for modeling. In this step, we might perform some feature engineering and

111
00:06:32,262 --> 00:06:35,542
create some new columns. We might fill in some missing values and, and a

112
00:06:35,558 --> 00:06:38,902
whole bunch of other data preparation steps, like, for example,

113
00:06:38,958 --> 00:06:42,670
splitting our data into training and testing. Next, we've got my

114
00:06:42,702 --> 00:06:45,814
favorite, which is modeling. This is all to do with training your machine

115
00:06:45,854 --> 00:06:49,630
learning algorithms to perform well on a specific task.

116
00:06:49,782 --> 00:06:53,798
Once we've trained our models in that modeling step, we get onto evaluation.

117
00:06:53,966 --> 00:06:56,670
Given that we've trained our model, we want to make sure that it's going to

118
00:06:56,702 --> 00:06:59,902
work well once we deploy it into the real world. This is what

119
00:06:59,918 --> 00:07:03,760
the evaluation step is all about. In this step, we try to check whether

120
00:07:03,792 --> 00:07:07,936
or not our model is likely to perform well using specific evaluation metrics.

121
00:07:08,000 --> 00:07:11,304
Now, once we've gone through all of that, the last step is to go and

122
00:07:11,344 --> 00:07:14,728
deploy our model. In order to deploy our model, we could release it as a

123
00:07:14,736 --> 00:07:18,376
rest API, containerize it up or save it as a binary so

124
00:07:18,400 --> 00:07:21,616
we can go and use it elsewhere. Now, a great way to

125
00:07:21,640 --> 00:07:25,368
remember CrispDM is to remember Barry drove directly to the medical

126
00:07:25,456 --> 00:07:29,112
emergency department. That way you remember business understanding data,

127
00:07:29,168 --> 00:07:33,234
understanding data preparation, modeling, evaluation, and deployment.

128
00:07:33,344 --> 00:07:36,606
Now, I've talked a lot about theory, but where do the python packages that

129
00:07:36,630 --> 00:07:40,470
you typically see used fit into this framework? Well, in terms

130
00:07:40,502 --> 00:07:44,206
of data science, numpy, pandas and Matplotlib are probably going to be the most

131
00:07:44,270 --> 00:07:47,942
important packages that you see floating around. Numpy and pandas

132
00:07:47,998 --> 00:07:51,510
help you traverse and explore your data and really work with your

133
00:07:51,542 --> 00:07:55,222
data. In terms of performing manipulations and data preparation,

134
00:07:55,358 --> 00:07:58,622
Matplotlib and Seaborn help you visualize that data and

135
00:07:58,678 --> 00:08:02,584
explore it even further. Now, the most important library in terms of machine learning

136
00:08:02,624 --> 00:08:05,784
is probably scikit learn. So scikit learn has been around for quite

137
00:08:05,824 --> 00:08:09,232
some time and gives you a whole bunch of really

138
00:08:09,288 --> 00:08:12,840
powerful algorithms and utilities to help use them to train your

139
00:08:12,872 --> 00:08:16,360
machine learning models. Now, deep learning is becoming increasingly

140
00:08:16,392 --> 00:08:20,280
popular, and there's a large number of libraries that can help you perform deep

141
00:08:20,312 --> 00:08:23,352
learning, some of which, which are notable, are tensorflow,

142
00:08:23,408 --> 00:08:26,908
Keras, Pytorch, and piano, just to name a few.

143
00:08:27,036 --> 00:08:30,812
And that about wraps up AI versus ML versus DL versus

144
00:08:30,868 --> 00:08:34,716
ds. Thanks so much for tuning in, guys. Hopefully you found this video useful.

145
00:08:34,780 --> 00:08:37,956
If you did, be sure to give it a thumbs up and hit subscribe until

146
00:08:38,020 --> 00:08:38,676
next time.

